# Copyright (c) 2023-2024, Crash Override, Inc.
#
# This file is part of Chalk
# (see https://crashoverride.com/docs/chalk)
import re
import shutil
from pathlib import Path

import os
import pytest

from .chalk.runner import Chalk, ChalkMark
from .chalk.validate import (
    ArtifactInfo,
    validate_chalk_report,
    validate_docker_chalk_report,
    validate_extracted_chalk,
    validate_virtual_chalk,
)
from .conf import CODEOWNERS, CONFIGS, DATA, DOCKERFILES, LS_PATH, PYS
from .utils.dict import ANY
from .utils.docker import Docker
from .utils.git import Git
from .utils.log import get_logger
from .utils.tmp import make_tmp_file


logger = get_logger()


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_network(copy_files: list[Path], chalk: Chalk):
    bin_path = copy_files[0]
    insert = chalk.insert(bin_path)
    assert insert.report.has(
        _NETWORK_PARTIAL_TRACEROUTE_IPS={
            "1.1.1.1": {
                "1": ANY,
                "2": ANY,
            },
        },
    )


def test_codeowners(tmp_data_dir: Path, chalk: Chalk):
    folder = CODEOWNERS / "raw1"
    expected_owners = (folder / "CODEOWNERS").read_text()
    shutil.copytree(folder, tmp_data_dir, dirs_exist_ok=True)
    artifact_info = ArtifactInfo.all_shebangs()
    assert len(artifact_info) == 1
    artifact = Path(list(artifact_info.keys())[0])
    Git(tmp_data_dir).init().add().commit()

    # chalk reports generated by insertion, json array that has one element
    insert = chalk.insert(artifact=artifact, virtual=True)
    assert insert.mark["CODE_OWNERS"] == expected_owners
    # check chalk report
    validate_chalk_report(
        chalk_report=insert.report, artifact_map=artifact_info, virtual=True
    )

    # array of json chalk objects as output, of which we are only expecting one
    extract = chalk.extract(artifact=tmp_data_dir)
    validate_extracted_chalk(
        extracted_chalk=extract.report, artifact_map=artifact_info, virtual=True
    )
    validate_virtual_chalk(
        tmp_data_dir=tmp_data_dir, artifact_map=artifact_info, virtual=True
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_github(copy_files: list[Path], chalk: Chalk, server_imds: str):
    bin_path = copy_files[0]
    artifact = ArtifactInfo.one_elf(
        bin_path,
        host_info={
            "BUILD_ID": "1658821493",
            "BUILD_COMMIT_ID": "ffac537e6cbbf934b08745a378932722df287a53",
            "BUILD_TRIGGER": "tag",
            "BUILD_CONTACT": ["octocat"],
            "BUILD_URI": "https://github.com/octocat/Hello-World/actions/runs/1658821493/attempts/5",
            "BUILD_API_URI": server_imds,
            "BUILD_ORIGIN_ID": "123",
            "BUILD_ORIGIN_KEY": "abc",
            "BUILD_ORIGIN_OWNER_ID": "456",
            "BUILD_ORIGIN_OWNER_KEY": "xyz",
        },
    )
    insert = chalk.insert(
        bin_path,
        env={
            # https://docs.github.com/en/actions/learn-github-actions/variables#default-environment-variables
            "CI": "true",
            "GITHUB_SHA": "ffac537e6cbbf934b08745a378932722df287a53",
            "GITHUB_SERVER_URL": "https://github.com",
            "GITHUB_REPOSITORY": "octocat/Hello-World",
            "GITHUB_RUN_ID": "1658821493",
            "GITHUB_RUN_ATTEMPT": "5",
            "GITHUB_API_URL": server_imds,
            "GITHUB_ACTOR": "octocat",
            "GITHUB_REPOSITORY_ID": "123",
            "GITHUB_REPOSITORY_OWNER_ID": "456",
            # there are a bunch of variations of these
            # but for now at least we test basic flow
            "GITHUB_EVENT_NAME": "push",
            "GITHUB_REF_TYPE": "tag",
        },
    )

    validate_chalk_report(
        chalk_report=insert.report,
        artifact_map=artifact,
        virtual=False,
        chalk_action="insert",
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_gitlab(copy_files: list[Path], chalk: Chalk):
    bin_path = copy_files[0]
    artifact = ArtifactInfo.one_elf(
        bin_path,
        host_info={
            "BUILD_ID": "4999820578",
            "BUILD_COMMIT_ID": "ffac537e6cbbf934b08745a378932722df287a53",
            "BUILD_TRIGGER": "push",
            "BUILD_CONTACT": ["user"],
            "BUILD_URI": "https://gitlab.com/gitlab-org/gitlab/-/jobs/4999820578",
            "BUILD_API_URI": "https://gitlab.com/api/v4",
            "BUILD_ORIGIN_ID": "123",
            "BUILD_ORIGIN_OWNER_ID": "456",
        },
    )
    insert = chalk.insert(
        bin_path,
        env={
            # https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
            "CI": "true",
            "GITLAB_CI": "true",
            "CI_COMMIT_SHA": "ffac537e6cbbf934b08745a378932722df287a53",
            "CI_JOB_URL": "https://gitlab.com/gitlab-org/gitlab/-/jobs/4999820578",
            "CI_JOB_ID": "4999820578",
            "CI_API_V4_URL": "https://gitlab.com/api/v4",
            "GITLAB_USER_LOGIN": "user",
            "CI_PIPELINE_SOURCE": "push",
            "CI_PROJECT_ID": "123",
            "CI_PROJECT_NAMESPACE_ID": "456",
        },
    )
    validate_chalk_report(
        chalk_report=insert.report,
        artifact_map=artifact,
        virtual=False,
        chalk_action="insert",
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_aws_no_imds(
    copy_files: list[Path],
    chalk: Chalk,
    server_imds: str,
):
    with make_tmp_file() as vendor, make_tmp_file() as instance:
        # make imds plugin think we are running in EC2
        vendor.write_text("Amazon EC2")
        instance.write_text("i-abc123xyz789")
        bin_path = copy_files[0]
        insert = chalk.insert(
            bin_path,
            config=CONFIGS / "imds.c4m",
            env={
                "VENDOR": str(vendor),
                "METADATA_IP": "imds",
                "INSTANCE": str(instance),
            },
        )
        assert insert.report.contains(
            {
                "_OP_CLOUD_SYS_VENDOR": "Amazon EC2",
                "_OP_CLOUD_PROVIDER": "aws",
                "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_ec2",
                "_OP_FAILED_KEYS": {
                    "_OP_CLOUD_METADATA": {
                        "code": "IMDS_DISABLED",
                    },
                },
                "_AWS_INSTANCE_ID": "i-abc123xyz789",
            }
        )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_imds(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    # make imds plugin think we are running in EC2
    tmp_file.write_text("Amazon")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "imds.c4m",
        env={"VENDOR": str(tmp_file)},
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "aws",
            "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_ec2",
            "_AWS_AMI_ID": "ami-0abcdef1234567890",
            "_AWS_AMI_LAUNCH_INDEX": "0",
            "_AWS_AMI_MANIFEST_PATH": "(unknown)",
            "_AWS_AZ": "us-east-1e",
            "_AWS_AZ_ID": "use1-az3",
            "_AWS_HOSTNAME": "ip-10-251-50-12.ec2.internal",
            "_AWS_IAM_INFO": {
                "Code": "Success",
                "LastUpdated": "2023-09-12T15:16:58Z",
                "InstanceProfileArn": "arn:aws:iam::123456789012:instance-profile/IMDSTestEc2Role",
                "InstanceProfileId": "AIPATILQWXT62BCWDUQCT",
            },
            "_AWS_INSTANCE_ID": "i-abc123xyz789",
            "_AWS_MAC": "00:25:96:FF:FE:12:34:56",
            "_AWS_VPC_ID": "vpc-1234567890",
            "_AWS_SUBNET_ID": "subnet-1234567890",
            "_AWS_INTERFACE_ID": "eni-1234567890",
            "_AWS_SECURITY_GROUPS": {"default", "test"},
            "_AWS_SECURITY_GROUP_IDS": {"sg-1234567890", "sg-098764321"},
            "_AWS_INSTANCE_IDENTITY_DOCUMENT": {
                "accountId": "123456789012",
                "architecture": "x86_64",
                "availabilityZone": "us-east-1e",
                "billingProducts": None,
                "devpayProductCodes": None,
                "marketplaceProductCodes": None,
                "imageId": "ami-0abcdef1234567890",
                "instanceId": "i-abc123xyz789",
                "instanceType": "t2.medium",
                "kernelId": None,
                "pendingTime": "2023-09-11T06:01:38Z",
                "privateIp": "10.251.50.12",
                "ramdiskId": None,
                "region": "us-east-1",
                "version": "2017-09-30",
            },
            "_AWS_INSTANCE_IDENTITY_PKCS7": re.compile(r"^.*=+$"),
            "_AWS_INSTANCE_IDENTITY_SIGNATURE": re.compile(r"^.*=+$"),
            "_AWS_INSTANCE_LIFE_CYCLE": "on-demand",
            "_AWS_INSTANCE_TYPE": "t2.medium",
            "_AWS_LOCAL_HOSTNAME": "ip-10-251-50-12.ec2.internal",
            "_AWS_LOCAL_IPV4_ADDR": "10.251.50.12",
            "_AWS_OPENSSH_PUBKEY": re.compile(r"^ssh-rsa .* test$"),
            "_AWS_PARTITION_NAME": "aws",
            "_AWS_PUBLIC_HOSTNAME": "ec2-203-0-113-25.compute-1.amazonaws.com",
            "_AWS_PUBLIC_IPV4_ADDR": "203.0.113.25",
            "_AWS_REGION": "us-east-1",
            "_AWS_RESOURCE_DOMAIN": "amazonaws.com",
            "_AWS_TAGS": {
                "Name": "foobar",
                "Environment": "staging",
            },
            "_AWS_IDENTITY_CREDENTIALS_EC2_INFO": {
                "Code": "Success",
                "LastUpdated": "2023-09-13T13:13:39Z",
                "AccountId": "123456789012",
            },
            "_AWS_IDENTITY_CREDENTIALS_EC2_SECURITY_CREDENTIALS_EC2_INSTANCE": {
                "Code": "Success",
                "LastUpdated": "2023-09-13T13:12:26Z",
                "Type": "AWS-HMAC",
                "AccessKeyId": "ASIATILQWXT67VGGR4O2",
                "SecretAccessKey": "<<redacted>>",
                "Token": "<<redacted>>",
                "Expiration": "2023-09-13T19:40:12Z",
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_ecs(
    copy_files: list[Path],
    chalk: Chalk,
    server_imds: str,
):
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        env={"ECS_CONTAINER_METADATA_URI": f"{server_imds}/ecs"},
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "aws",
            "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_ecs",
            "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": "123456789012",
            "_OP_CLOUD_PROVIDER_REGION": "us-east-1",
            "_AWS_REGION": "us-east-1",
            "_OP_CLOUD_METADATA": {
                "aws_ecs": {
                    "container": dict,
                    "task": dict,
                    "task/stats": dict,
                },
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_lambda(
    copy_files: list[Path],
    chalk: Chalk,
):
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        env={
            "AWS_LAMBDA_FUNCTION_NAME": "dummy",
            "AWS_LAMBDA_FUNCTION_VERSION": "2",
            "AWS_LAMBDA_LOG_GROUP_NAME": "/aws/logs",
            "AWS_LAMBDA_LOG_STREAM_NAME": "2023/12/25/[$LATEST]f42d28eb350e42a1b840ad55fd5232fe",
            "AWS_DEFAULT_REGION": "us-east-1",
        },
    )
    top, meta = (
        (
            {
                "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": re.compile(r"[\d]+"),
            },
            {
                "AWS_LAMBDA_FUNCTION_ARN": re.compile(r"^arn:"),
                "AWS_LAMBDA_VERSION_ARN": re.compile(r"^arn:"),
                "AWS_LAMBDA_LOG_STREAM_ARN": re.compile(r"^arn:"),
                "AWS_ROLE_ARN": re.compile(r"^arn:"),
                "AWS_ACCOUNT_ID": re.compile(r"[\d]+"),
            },
        )
        if os.environ.get("AWS_ACCESS_KEY_ID")
        else ({}, {})
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "aws",
            "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_lambda",
            "_OP_CLOUD_PROVIDER_REGION": "us-east-1",
            "_AWS_REGION": "us-east-1",
            "_OP_CLOUD_METADATA": {
                "aws_lambda": {
                    "AWS_LAMBDA_FUNCTION_NAME": "dummy",
                    "AWS_LAMBDA_FUNCTION_VERSION": "2",
                    "AWS_LAMBDA_LOG_GROUP_NAME": "/aws/logs",
                    "AWS_LAMBDA_LOG_STREAM_NAME": "2023/12/25/[$LATEST]f42d28eb350e42a1b840ad55fd5232fe",
                    "AWS_REGION": "us-east-1",
                    **meta,
                },
            },
            **top,
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_imds_ecs(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    # make imds plugin think we are running in EC2
    tmp_file.write_text("Amazon")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "imds.c4m",
        env={
            "ECS_CONTAINER_METADATA_URI": f"{server_imds}/ecs",
            "VENDOR": str(tmp_file),
        },
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "aws",
            "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_ecs",
            "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": "123456789012",
            "_OP_CLOUD_PROVIDER_IP": "203.0.113.25",
            "_OP_CLOUD_PROVIDER_REGION": "us-east-1",
            "_OP_CLOUD_PROVIDER_INSTANCE_TYPE": "t2.medium",
            "_OP_CLOUD_PROVIDER_TAGS": {
                "Name": "foobar",
                "Environment": "staging",
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_imds_eks(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    # make imds plugin think we are running in EC2
    tmp_file.write_text("Amazon")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "imds.c4m",
        env={
            "KUBERNETES_PORT": "tests",
            "VENDOR": str(tmp_file),
        },
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "aws",
            "_OP_CLOUD_PROVIDER_SERVICE_TYPE": "aws_eks",
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_metadata_azure(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    # make imds plugin think we are running in EC2
    tmp_file.write_text("Microsoft Corporation")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "imds.c4m",
        env={
            "VENDOR": str(tmp_file),
        },
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "azure",
            "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": "11111111-1111-1111-1111-111111111111",
            "_OP_CLOUD_PROVIDER_IP": "20.242.32.12",
            "_OP_CLOUD_PROVIDER_REGION": "westeurope",
            "_OP_CLOUD_PROVIDER_INSTANCE_TYPE": "Standard_B1ls",
            "_OP_CLOUD_PROVIDER_TAGS": [
                {"name": "testtag", "value": "testvalue"},
                {"name": "testtag2", "value": "testvalue2"},
            ],
            "_AZURE_INSTANCE_METADATA": {
                "compute": {
                    "azEnvironment": "AzurePublicCloud",
                    "customData": "",
                    "evictionPolicy": "",
                    "isHostCompatibilityLayerVm": "true",
                    "licenseType": "",
                    "location": "westeurope",
                    "name": "myVm",
                    "offer": "0001-com-ubuntu-server-focal",
                    "osProfile": {
                        "adminUsername": "testuser",
                        "computerName": "myVm",
                        "disablePasswordAuthentication": "true",
                    },
                    "osType": "Linux",
                    "placementGroupId": "",
                    "plan": {"name": "", "product": "", "publisher": ""},
                    "platformFaultDomain": "0",
                    "platformUpdateDomain": "0",
                    "priority": "",
                    "provider": "Microsoft.Compute",
                    "publicKeys": [
                        {
                            "keyData": "ssh-rsa AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJQPr4RsDbaJdKPHl2gfCwiWcTRVEu0XlQvsPgdvCH/Io8Im1VfBMamtRhTIEqlEoTaRD8h9ETDQAPg7GUVkg07P3ZgDfFf94KePpxADso7GoqaPsGuL4OQpURa4DQCmf1Jw+kDg0TI1ERYIQoNOGduiS5cuB74A5BxcgW2A52ocVoiINS1tPudZBIvnr8iQXa6BhB5EgUVP0w+pGaOgI4jHga8ThT9weGqzBrtBcyiZ44jfT2Tg/AjI4GuXq14HdFEN0096vk= generated-by-azure",
                            "path": "/home/testuser/.ssh/authorized_keys",
                        }
                    ],
                    "publisher": "canonical",
                    "resourceGroupName": "myVm_group",
                    "resourceId": "/subscriptions/11111111-1111-1111-1111-111111111111/resourceGroups/myVm_group/providers/Microsoft.Compute/virtualMachines/myVm",
                    "securityProfile": {
                        "secureBootEnabled": "true",
                        "virtualTpmEnabled": "true",
                    },
                    "sku": "20_04-lts-gen2",
                    "storageProfile": {
                        "dataDisks": [],
                        "imageReference": {
                            "id": "",
                            "offer": "0001-com-ubuntu-server-focal",
                            "publisher": "canonical",
                            "sku": "20_04-lts-gen2",
                            "version": "latest",
                        },
                        "osDisk": {
                            "caching": "ReadWrite",
                            "createOption": "FromImage",
                            "diffDiskSettings": {"option": ""},
                            "diskSizeGB": "30",
                            "encryptionSettings": {"enabled": "false"},
                            "image": {"uri": ""},
                            "managedDisk": {
                                "id": "/subscriptions/11111111-1111-1111-1111-111111111111/resourceGroups/myVm_group/providers/Microsoft.Compute/disks/myVm_disk1_5e2103587ca646929255128ff64b5bdb",
                                "storageAccountType": "Premium_LRS",
                            },
                            "name": "myVm_disk1_5e2103587ca646929255128ff64b5bdb",
                            "osType": "Linux",
                            "vhd": {"uri": ""},
                            "writeAcceleratorEnabled": "false",
                        },
                        "resourceDisk": {"size": "34816"},
                    },
                    "subscriptionId": "11111111-1111-1111-1111-111111111111",
                    "tags": "testtag:testvalue;testtag2:testvalue2",
                    "tagsList": [
                        {"name": "testtag", "value": "testvalue"},
                        {"name": "testtag2", "value": "testvalue2"},
                    ],
                    "userData": "",
                    "version": "20.04.202308310",
                    "vmId": "e94f3f7f-6b23-4395-be46-ea363c549f71",
                    "vmScaleSetName": "",
                    "vmSize": "Standard_B1ls",
                    "zone": "2",
                },
                "network": {
                    "interface": [
                        {
                            "ipv4": {
                                "ipAddress": [
                                    {
                                        "privateIpAddress": "10.0.0.4",
                                        "publicIpAddress": "20.242.32.12",
                                    }
                                ],
                                "subnet": [{"address": "10.0.0.0", "prefix": "24"}],
                            },
                            "ipv6": {"ipAddress": []},
                            "macAddress": "AAAAAAAAAAAA",
                        }
                    ]
                },
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_metadata_gcp_no_vendor(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    tmp_file.write_text("search google.internal.")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "resolv.c4m",
        env={
            "TEST_RESOLV": str(tmp_file),
            "CLOUD_RUN_TIMEOUT_SECONDS": "120",
            "K_SERVICE": "test",
        },
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "gcp",
            "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": {
                "11111111111-compute@developer.gserviceaccount.com": {
                    "aliases": ["default"],
                    "email": "11111111111-compute@developer.gserviceaccount.com",
                    "scopes": [
                        "https://www.googleapis.com/auth/devstorage.read_only",
                        "https://www.googleapis.com/auth/logging.write",
                        "https://www.googleapis.com/auth/monitoring.write",
                        "https://www.googleapis.com/auth/servicecontrol",
                        "https://www.googleapis.com/auth/service.management.readonly",
                        "https://www.googleapis.com/auth/trace.append",
                    ],
                },
                "default": {
                    "aliases": ["default"],
                    "email": "11111111111-compute@developer.gserviceaccount.com",
                    "scopes": [
                        "https://www.googleapis.com/auth/devstorage.read_only",
                        "https://www.googleapis.com/auth/logging.write",
                        "https://www.googleapis.com/auth/monitoring.write",
                        "https://www.googleapis.com/auth/servicecontrol",
                        "https://www.googleapis.com/auth/service.management.readonly",
                        "https://www.googleapis.com/auth/trace.append",
                    ],
                },
            },
            "_OP_CLOUD_PROVIDER_IP": "35.205.62.123",
            "_OP_CLOUD_PROVIDER_REGION": "europe-west1-b",
            "_OP_CLOUD_PROVIDER_INSTANCE_TYPE": "e2-micro",
            "_GCP_PROJECT_METADATA": {
                "numericProjectId": 434557252559,
                "projectId": "gcp-integration-423910",
            },
            "_GCP_INSTANCE_METADATA": {
                "attributes": {
                    "ssh-keys": 'test:ecdsa-sha2-nistp256 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKgXTiO1+sSWCEsq/bWaLdY= google-ssh {"userName":"test@crashoverride.com","expireOn":"2023-10-14T15:11:57+0000"}\ntest:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCvddnbJ/XWxMUPXOsDMNoRHJeaCgwqk6g7UYvrXqogwmJ1WpC1QPuG3mhDjmBOcjINi7TYsozDKZilL2BDu2i6CGC1s2Tokq41lsgnCePNdnYmPcA318PmuMmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeT7R92kx google-ssh {"userName":"test@crashoverride.com","expireOn":"2023-10-14T15:12:12+0000"}'
                },
                "cpuPlatform": "Intel Broadwell",
                "description": "",
                "disks": [
                    {
                        "deviceName": "instance-1",
                        "index": 0,
                        "interface": "SCSI",
                        "mode": "READ_WRITE",
                        "type": "PERSISTENT-BALANCED",
                    }
                ],
                "guestAttributes": {},
                "hostname": "instance-1.europe-west1-b.c.test-chalk-402014.internal",
                "id": 133380848178631130,
                "image": "projects/debian-cloud/global/images/debian-11-bullseye-v20231010",
                "licenses": [{"id": "4324324324234234234"}],
                "machineType": "projects/11111111111/machineTypes/e2-micro",
                "maintenanceEvent": "NONE",
                "name": "instance-1",
                "networkInterfaces": [
                    {
                        "accessConfigs": [
                            {"externalIp": "35.205.62.123", "type": "ONE_TO_ONE_NAT"}
                        ],
                        "dnsServers": ["169.254.169.254"],
                        "forwardedIps": [],
                        "gateway": "10.132.0.1",
                        "ip": "10.132.0.2",
                        "ipAliases": [],
                        "mac": "42:01:0a:84:00:02",
                        "mtu": 1460,
                        "network": "projects/11111111111/networks/default",
                        "subnetmask": "255.255.240.0",
                        "targetInstanceIps": [],
                    }
                ],
                "partnerAttributes": {},
                "preempted": "FALSE",
                "remainingCpuTime": -1,
                "scheduling": {
                    "automaticRestart": "TRUE",
                    "onHostMaintenance": "MIGRATE",
                    "preemptible": "FALSE",
                },
                "serviceAccounts": {
                    "11111111111-compute@developer.gserviceaccount.com": {
                        "aliases": ["default"],
                        "email": "11111111111-compute@developer.gserviceaccount.com",
                        "scopes": [
                            "https://www.googleapis.com/auth/devstorage.read_only",
                            "https://www.googleapis.com/auth/logging.write",
                            "https://www.googleapis.com/auth/monitoring.write",
                            "https://www.googleapis.com/auth/servicecontrol",
                            "https://www.googleapis.com/auth/service.management.readonly",
                            "https://www.googleapis.com/auth/trace.append",
                        ],
                    },
                    "default": {
                        "aliases": ["default"],
                        "email": "11111111111-compute@developer.gserviceaccount.com",
                        "scopes": [
                            "https://www.googleapis.com/auth/devstorage.read_only",
                            "https://www.googleapis.com/auth/logging.write",
                            "https://www.googleapis.com/auth/monitoring.write",
                            "https://www.googleapis.com/auth/servicecontrol",
                            "https://www.googleapis.com/auth/service.management.readonly",
                            "https://www.googleapis.com/auth/trace.append",
                        ],
                    },
                },
                "tags": [],
                "virtualClock": {"driftToken": "0"},
                "zone": "projects/11111111111/zones/europe-west1-b",
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_metadata_gcp(
    copy_files: list[Path],
    chalk: Chalk,
    tmp_file: Path,
    server_imds: str,
):
    tmp_file.write_text("Google")
    bin_path = copy_files[0]
    insert = chalk.insert(
        bin_path,
        config=CONFIGS / "imds.c4m",
        env={"VENDOR": str(tmp_file)},
    )
    assert insert.report.contains(
        {
            "_OP_CLOUD_PROVIDER": "gcp",
            "_OP_CLOUD_PROVIDER_ACCOUNT_INFO": {
                "11111111111-compute@developer.gserviceaccount.com": {
                    "aliases": ["default"],
                    "email": "11111111111-compute@developer.gserviceaccount.com",
                    "scopes": [
                        "https://www.googleapis.com/auth/devstorage.read_only",
                        "https://www.googleapis.com/auth/logging.write",
                        "https://www.googleapis.com/auth/monitoring.write",
                        "https://www.googleapis.com/auth/servicecontrol",
                        "https://www.googleapis.com/auth/service.management.readonly",
                        "https://www.googleapis.com/auth/trace.append",
                    ],
                },
                "default": {
                    "aliases": ["default"],
                    "email": "11111111111-compute@developer.gserviceaccount.com",
                    "scopes": [
                        "https://www.googleapis.com/auth/devstorage.read_only",
                        "https://www.googleapis.com/auth/logging.write",
                        "https://www.googleapis.com/auth/monitoring.write",
                        "https://www.googleapis.com/auth/servicecontrol",
                        "https://www.googleapis.com/auth/service.management.readonly",
                        "https://www.googleapis.com/auth/trace.append",
                    ],
                },
            },
            "_OP_CLOUD_PROVIDER_IP": "35.205.62.123",
            "_OP_CLOUD_PROVIDER_REGION": "europe-west1-b",
            "_OP_CLOUD_PROVIDER_INSTANCE_TYPE": "e2-micro",
            "_GCP_PROJECT_METADATA": {
                "numericProjectId": 434557252559,
                "projectId": "gcp-integration-423910",
            },
            "_GCP_INSTANCE_METADATA": {
                "attributes": {
                    "ssh-keys": 'test:ecdsa-sha2-nistp256 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKgXTiO1+sSWCEsq/bWaLdY= google-ssh {"userName":"test@crashoverride.com","expireOn":"2023-10-14T15:11:57+0000"}\ntest:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCvddnbJ/XWxMUPXOsDMNoRHJeaCgwqk6g7UYvrXqogwmJ1WpC1QPuG3mhDjmBOcjINi7TYsozDKZilL2BDu2i6CGC1s2Tokq41lsgnCePNdnYmPcA318PmuMmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeT7R92kx google-ssh {"userName":"test@crashoverride.com","expireOn":"2023-10-14T15:12:12+0000"}'
                },
                "cpuPlatform": "Intel Broadwell",
                "description": "",
                "disks": [
                    {
                        "deviceName": "instance-1",
                        "index": 0,
                        "interface": "SCSI",
                        "mode": "READ_WRITE",
                        "type": "PERSISTENT-BALANCED",
                    }
                ],
                "guestAttributes": {},
                "hostname": "instance-1.europe-west1-b.c.test-chalk-402014.internal",
                "id": 133380848178631130,
                "image": "projects/debian-cloud/global/images/debian-11-bullseye-v20231010",
                "licenses": [{"id": "4324324324234234234"}],
                "machineType": "projects/11111111111/machineTypes/e2-micro",
                "maintenanceEvent": "NONE",
                "name": "instance-1",
                "networkInterfaces": [
                    {
                        "accessConfigs": [
                            {"externalIp": "35.205.62.123", "type": "ONE_TO_ONE_NAT"}
                        ],
                        "dnsServers": ["169.254.169.254"],
                        "forwardedIps": [],
                        "gateway": "10.132.0.1",
                        "ip": "10.132.0.2",
                        "ipAliases": [],
                        "mac": "42:01:0a:84:00:02",
                        "mtu": 1460,
                        "network": "projects/11111111111/networks/default",
                        "subnetmask": "255.255.240.0",
                        "targetInstanceIps": [],
                    }
                ],
                "partnerAttributes": {},
                "preempted": "FALSE",
                "remainingCpuTime": -1,
                "scheduling": {
                    "automaticRestart": "TRUE",
                    "onHostMaintenance": "MIGRATE",
                    "preemptible": "FALSE",
                },
                "serviceAccounts": {
                    "11111111111-compute@developer.gserviceaccount.com": {
                        "aliases": ["default"],
                        "email": "11111111111-compute@developer.gserviceaccount.com",
                        "scopes": [
                            "https://www.googleapis.com/auth/devstorage.read_only",
                            "https://www.googleapis.com/auth/logging.write",
                            "https://www.googleapis.com/auth/monitoring.write",
                            "https://www.googleapis.com/auth/servicecontrol",
                            "https://www.googleapis.com/auth/service.management.readonly",
                            "https://www.googleapis.com/auth/trace.append",
                        ],
                    },
                    "default": {
                        "aliases": ["default"],
                        "email": "11111111111-compute@developer.gserviceaccount.com",
                        "scopes": [
                            "https://www.googleapis.com/auth/devstorage.read_only",
                            "https://www.googleapis.com/auth/logging.write",
                            "https://www.googleapis.com/auth/monitoring.write",
                            "https://www.googleapis.com/auth/servicecontrol",
                            "https://www.googleapis.com/auth/service.management.readonly",
                            "https://www.googleapis.com/auth/trace.append",
                        ],
                    },
                },
                "tags": [],
                "virtualClock": {"driftToken": "0"},
                "zone": "projects/11111111111/zones/europe-west1-b",
            },
        }
    )


@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_tech_stack(chalk_copy: Chalk, copy_files: list[Path]):
    bin_path = copy_files[0]
    parent = bin_path.parent
    (parent / "test.nim").write_text("")
    (parent / "test.php").write_text("")
    result = chalk_copy.insert(
        bin_path,
        config=CONFIGS / "techstack.c4m",
    )
    assert result.mark.has(
        INFERRED_TECH_STACKS={"language": {"PHP", "Nim"}},
    )
    assert result.report.has(
        _INFERRED_TECH_STACKS_HOST={
            "framework": {
                "other",
            }
        }
    )


@pytest.mark.parametrize("test_file", ["valid/sample_1"])
def test_syft_docker(chalk_copy: Chalk, test_file: str, random_hex: str):
    # we need to enable sboms + embed sboms
    chalk = chalk_copy
    chalk.load(
        config=CONFIGS / "composable" / "valid" / "sboms" / "enable_sboms.c4m",
        replace=False,
    )

    # expected sbom output
    # stripped to show basics only in case we change versions
    sbom_data = {
        "SBOM": {
            "syft": {
                "bomFormat": "CycloneDX",
                "metadata": {
                    "component": {
                        "type": "file",
                        "name": re.compile(
                            r"tests/functional/data/dockerfiles/valid/sample_1$"
                        ),
                    },
                },
            }
        }
    }

    tag = f"{test_file}_{random_hex}"
    image_hash, build = chalk.docker_build(
        dockerfile=DOCKERFILES / test_file / "Dockerfile",
        tag=tag,
    )

    # artifact is the docker image
    artifact_info = ArtifactInfo(
        type="Docker Image",
        # keys to check
        host_info=sbom_data,
    )
    validate_docker_chalk_report(
        chalk_report=build.report, artifact=artifact_info, virtual=False
    )

    # check sbom data from running container
    _, result = Docker.run(
        image=image_hash,
        entrypoint="cat",
        params=["chalk.json"],
    )
    chalk_mark = ChalkMark.from_json(result.stdout.decode())

    assert chalk_mark.contains(sbom_data)


@pytest.mark.parametrize("use_docker", [True, False])
@pytest.mark.parametrize("copy_files", [[LS_PATH]], indirect=True)
def test_syft_binary(copy_files: list[Path], chalk_copy: Chalk, use_docker: bool):
    bin_path = copy_files[0]

    # we need to enable sboms + embed sboms so load test config
    chalk = chalk_copy
    chalk.load(
        config=CONFIGS / "composable" / "valid" / "sboms" / "enable_sboms.c4m",
        replace=False,
    )

    # expected sbom output
    # stripped to show basics only in case we change versions
    sbom_data = {
        "SBOM": {
            "syft": {
                "bomFormat": "CycloneDX",
                "metadata": {
                    "component": {
                        "type": "file",
                        "name": "ls",
                    },
                },
            }
        }
    }

    artifact = ArtifactInfo.one_elf(bin_path, chalk_info=sbom_data)

    insert = chalk.insert(bin_path, env={"EXTERNAL_TOOL_USE_DOCKER": str(use_docker)})
    validate_chalk_report(
        chalk_report=insert.report,
        artifact_map=artifact,
        virtual=False,
        chalk_action="insert",
    )
    if use_docker:
        assert "ghcr.io/anchore/syft" in insert.logs
    else:
        assert "ghcr.io/anchore/syft" not in insert.logs

    # check that sbom has been embedded into the artifact
    chalk_mark = ChalkMark.from_binary(bin_path)
    assert chalk_mark.contains(sbom_data)


@pytest.mark.parametrize("use_docker", [True, False])
@pytest.mark.parametrize(
    "test_file",
    [
        "sample_1",
    ],
)
def test_semgrep(
    tmp_data_dir: Path, test_file: str, chalk_copy: Chalk, use_docker: bool
):
    shutil.copytree(PYS / test_file, tmp_data_dir, dirs_exist_ok=True)
    # copy rule.yaml also
    shutil.copy(DATA / "semgrep" / "rule.yaml", tmp_data_dir)

    # we need to enable sast + embed sast so load test config
    chalk = chalk_copy
    chalk.load(
        config=CONFIGS / "composable" / "valid" / "sast" / "enable_sast.c4m",
        replace=False,
    )

    # expected sast output with custom rule
    sast_data = {
        "SAST": {
            "semgrep": {
                "runs": [
                    {
                        "invocations": [
                            {
                                "executionSuccessful": True,
                            }
                        ],
                        "results": [
                            {
                                "locations": [
                                    {
                                        "physicalLocation": {
                                            "artifactLocation": {
                                                "uri": str(
                                                    tmp_data_dir / "helloworld.py"
                                                ),
                                                "uriBaseId": "%SRCROOT%",
                                            },
                                            "region": {
                                                "endColumn": int,
                                                "endLine": int,
                                                "snippet": {
                                                    "text": '    if test_var is "bbb":'
                                                },
                                                "startColumn": int,
                                                "startLine": int,
                                            },
                                        }
                                    }
                                ],
                                "message": {
                                    "text": re.compile(r"'is'.*=="),
                                },
                                "ruleId": "is-comparison",
                            }
                        ],
                        "tool": {
                            "driver": {
                                "name": "Semgrep OSS",
                                "rules": [
                                    {
                                        "id": "is-comparison",
                                        "name": "is-comparison",
                                    }
                                ],
                                "semanticVersion": ANY,
                            }
                        },
                    }
                ],
            }
        }
    }
    artifact = ArtifactInfo.one_elf(
        tmp_data_dir / "helloworld.py", chalk_info=sast_data
    )

    insert = chalk.insert(
        artifact=tmp_data_dir, env={"EXTERNAL_TOOL_USE_DOCKER": str(use_docker)}
    )
    validate_chalk_report(
        chalk_report=insert.report,
        artifact_map=artifact,
        virtual=False,
        chalk_action="insert",
    )
    if use_docker:
        assert "semgrep/semgrep" in insert.logs
    else:
        assert "semgrep/semgrep" not in insert.logs

    # check that sbom has been embedded into the artifact
    chalk_mark = ChalkMark.from_binary(tmp_data_dir / "helloworld.py")
    assert chalk_mark.contains(sast_data)
